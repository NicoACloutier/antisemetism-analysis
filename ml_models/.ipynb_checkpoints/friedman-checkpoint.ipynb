{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e5eb63e-3523-4bbd-9a97-dfec7496c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b6cc2c8-6530-4466-8f4e-2359abdb9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['binary', 'type']\n",
    "representations = ['bow', 'freq', 'tfidf']\n",
    "models = ['decision-tree', 'svm', 'naive-bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81fd1d76-08ec-486d-8d49-f5ff2b77eec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine columns in a dataframe whose names contain certain substrings\n",
    "def combine_columns(df, substrings):\n",
    "    '''\n",
    "    df: the input dataframe that has many column names that contain certain common substrings\n",
    "    substrings: the list of substrings used for combination\n",
    "    \n",
    "    returns: `output_df`, a DataFrame with `substrings` as its columns. Each row is the mean\n",
    "    of the value for that row of all of the columns in `df` that contained that substring.\n",
    "    '''\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    for column_substring in substrings:\n",
    "        temp_array = np.zeros(len(df))\n",
    "        to_be_combined = [column for column in df.columns.values if column_substring in column]\n",
    "        \n",
    "        for column in to_be_combined:\n",
    "            temp_array += np.array(df[column])\n",
    "            \n",
    "        output_df[column_substring] = temp_array\n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9170929b-2fae-45d6-9244-a4c955dd86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find which models performed best using basic accuracy score\n",
    "def evaluate_models(df, substrings):\n",
    "    output_df = pd.DataFrame()\n",
    "    temp_df = combine_columns(df, substrings)\n",
    "    for column in substrings:\n",
    "        temp_df[column] = temp_df[column] == df['Actual']\n",
    "        output_df[column] = [sum(temp_df[column])/len(temp_df),]\n",
    "    return output_df\n",
    "\n",
    "#test model significance difference w/ Friedman Chi^2 while combining certain columns\n",
    "def test_model_difference(df, substrings):\n",
    "    df = combine_columns(df, substrings)\n",
    "    friedman_result = stats.friedmanchisquare(\n",
    "        df[substrings[0]],\n",
    "        df[substrings[1]],\n",
    "        df[substrings[2]],\n",
    "        )\n",
    "    return friedman_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b3415c-0ebe-4943-8d45-68c7ebf4a99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: binary.\n",
      "Friedman chi square test p-value: 6.302286079316834e-89\n",
      "                                           0\n",
      "Actual                              1.000000\n",
      "svm-bow-classification              0.769672\n",
      "decision-tree-tfidf-classification  0.760656\n",
      "svm-freq-classification             0.757377\n",
      "decision-tree-freq-classification   0.756557\n",
      "svm-tfidf-classification            0.731967\n",
      "decision-tree-bow-classification    0.722131\n",
      "naive-bayes-bow-classification      0.638525\n",
      "naive-bayes-tfidf-classification    0.599180\n",
      "naive-bayes-freq-classification     0.591803\n",
      "\n",
      "Task: type.\n",
      "Friedman chi square test p-value: 2.5197389103373674e-29\n",
      "                                                 0\n",
      "Actual                                    1.000000\n",
      "svm-bow-type_of_antisemitism              0.582353\n",
      "decision-tree-bow-type_of_antisemitism    0.576471\n",
      "decision-tree-freq-type_of_antisemitism   0.567647\n",
      "decision-tree-tfidf-type_of_antisemitism  0.555882\n",
      "naive-bayes-freq-type_of_antisemitism     0.538235\n",
      "naive-bayes-tfidf-type_of_antisemitism    0.526471\n",
      "svm-freq-type_of_antisemitism             0.520588\n",
      "naive-bayes-bow-type_of_antisemitism      0.514706\n",
      "svm-tfidf-type_of_antisemitism            0.476471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    df = pd.read_csv(f'{task}_predictions.csv')\n",
    "    temp_df = evaluate_models(df, df.columns.values).transpose()\n",
    "    temp_df = temp_df.sort_values(0, ascending=False)\n",
    "    friedman_result = test_model_difference(df, df.columns.values[1:])\n",
    "    print(f'Task: {task}.')\n",
    "    print(f'Friedman chi square test p-value: {friedman_result.pvalue}')\n",
    "    print(temp_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b39c89a-eb6a-4782-98dc-6f70275246bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: binary. Grouping: ['bow', 'freq', 'tfidf'].\n",
      "Friedman chi square test p-value: 5.20681817543709e-10\n",
      "              0\n",
      "tfidf  0.550000\n",
      "freq   0.516393\n",
      "bow    0.506557\n",
      "\n",
      "Task: binary. Grouping: ['decision-tree', 'svm', 'naive-bayes'].\n",
      "Friedman chi square test p-value: 4.3991847899599944e-73\n",
      "                      0\n",
      "svm            0.713934\n",
      "decision-tree  0.568033\n",
      "naive-bayes    0.466393\n",
      "\n",
      "Task: type. Grouping: ['bow', 'freq', 'tfidf'].\n",
      "Friedman chi square test p-value: 8.366475064253767e-08\n",
      "              0\n",
      "tfidf  0.397059\n",
      "bow    0.347059\n",
      "freq   0.338235\n",
      "\n",
      "Task: type. Grouping: ['decision-tree', 'svm', 'naive-bayes'].\n",
      "Friedman chi square test p-value: 1.936914965049763e-23\n",
      "                      0\n",
      "svm            0.479412\n",
      "naive-bayes    0.320588\n",
      "decision-tree  0.300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    df = pd.read_csv(f'{task}_predictions.csv')\n",
    "    for grouping in [representations, models]:\n",
    "        temp_df = evaluate_models(df, grouping).transpose()\n",
    "        temp_df = temp_df.sort_values(0, ascending=False)\n",
    "        friedman_result = test_model_difference(df, grouping)\n",
    "        \n",
    "        print(f'Task: {task}. Grouping: {grouping[:3]}.')\n",
    "        print(f'Friedman chi square test p-value: {friedman_result.pvalue}')\n",
    "        print(temp_df)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e6a189-df97-4a27-8b86-8748b27ab020",
   "metadata": {},
   "source": [
    "It can be concluded that both the model and text representation have significant results on the predictions, especially the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
